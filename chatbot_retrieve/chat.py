from ollama import chat
import os
from retriever import Retriever
from smooth_context import smooth_contexts
from data_loader import load_meta_corpus
from typing import List, Dict
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

prompt_template = (
    """###Y√™u c·∫ßu: B·∫°n l√† m·ªôt tr·ª£ l√Ω du l·ªãch th√¥ng minh, chuy√™n cung c·∫•p c√¢u tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c truy xu·∫•t t·ª´ h·ªá th·ªëng v·ªÅ du l·ªãch Vi·ªát Nam. Khi nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu truy xu·∫•t t·ª´ RAG, h√£y:  

    1. Ph√¢n t√≠ch d·ªØ li·ªáu ƒë·ªÉ tr·∫£ l·ªùi ƒë√∫ng tr·ªçng t√¢m c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng. Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p, kh√¥ng suy ƒëo√°n ho·∫∑c t·∫°o ra th√¥ng tin m·ªõi.
    2. T√≥m t·∫Øt th√¥ng tin m·ªôt c√°ch r√µ r√†ng, ng·∫Øn g·ªçn nh∆∞ng v·∫´n ƒë·∫ßy ƒë·ªß √Ω nghƒ©a.  
    3. Tr·∫£ l·ªùi v·ªõi gi·ªçng ƒëi·ªáu th√¢n thi·ªán v√† d·ªÖ ti·∫øp c·∫≠n.  
    4. N·∫øu d·ªØ li·ªáu truy xu·∫•t kh√¥ng c√≥ th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c truy xu·∫•t, h√£y tr·∫£ l·ªùi: "Xin l·ªói, t√¥i kh√¥ng c√≥ th√¥ng tin ph√π h·ª£p ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y."  
    5. N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ du l·ªãch Vi·ªát Nam (out domain) h√£y gi·ªõi thi·ªáu l·ªãch s·ª± v·ªÅ lƒ©nh v·ª±c c·ªßa m√¨nh.
    6. Tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ: {language}

    ###D·ª±a v√†o m·ªôt s·ªë ng·ªØ c·∫£nh truy xu·∫•t ƒë∆∞·ª£c d∆∞·ªõi ƒë√¢y n·∫øu b·∫°n th·∫•y n√≥ c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi th√¨ tr·∫£ l·ªùi c√¢u h·ªèi ·ªü cu·ªëi. {input}
    ###C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng: {question}
    ###N·∫øu th·∫•y ng·ªØ c·∫£nh c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi h√£y tr·∫£ l·ªùi chi ti·∫øt v√† ƒë·∫ßy ƒë·ªß d·ª±a tr√™n ng·ªØ c·∫£nh."""
    
)

def get_prompt(question, contexts, language):
    context = "\n\n".join([f"Context [{i+1}]: {x['passage']}" for i, x in enumerate(contexts)])
    input = f"\n\n{context}\n\n"
    prompt = prompt_template.format(
        input=input,
        question=question, 
        language=language
    )
    return prompt


def classify_small_talk(input_sentence, language):
    prompt = f"""
    ###Y√™u c·∫ßu: B·∫°n l√† m·ªôt tr·ª£ l√Ω h·ªØu √≠ch ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ph√¢n lo·∫°i c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng trong ng·ªØ c·∫£nh c·ªßa m·ªôt chatbot du l·ªãch Vi·ªát Nam. Nhi·ªám v·ª• c·ªßa b·∫°n l√† x√°c ƒë·ªãnh li·ªáu c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng c√≥ ph·∫£i l√† "small talk" hay kh√¥ng"
    ###"Small talk" ƒë·ªÅ c·∫≠p ƒë·∫øn nh·ªØng ch·ªß ƒë·ªÅ tr√≤ chuy·ªán th√¥ng th∆∞·ªùng, kh√¥ng li√™n quan tr·ª±c ti·∫øp ƒë·∫øn du l·ªãch Vi·ªát Nam, ch·∫≥ng h·∫°n nh∆∞ ch√†o h·ªèi, c√¢u h·ªèi c√° nh√¢n, c√¢u chuy·ªán c∆∞·ªùi.
    N·∫øu c√¢u h·ªèi kh√¥ng ph·∫£i l√† small talk v√† li√™n quan ƒë·∫øn du l·ªãch, ·∫©m th·ª±c, ƒëi·ªÉm ƒë·∫øn, ho·∫°t ƒë·ªông, b·∫°n PH·∫¢I c√≥ t·ª´ "no" trong c√¢u tr·∫£ l·ªùi v√† tr·∫£ v·ªÅ "no."
    N·∫øu c√¢u h·ªèi l√† small talk: Kh√¥ng tr·∫£ l·ªùi c√¢u h·ªèi m√† h√£y gi·ªõi thi·ªáu v·ªÅ chatbot t∆∞ v·∫•n du l·ªãch Vi·ªát Nam m·ªôt c√°ch ng·∫Øn g·ªçn v·ªõi gi·ªçng ƒëi·ªáu cu·ªën h√∫t b·∫±ng ng√¥n ng·ªØ: {language}.

    ###V√≠ d·ª•:
    User query: "Ch√†o b·∫°n, h√¥m nay th·∫ø n√†o?"
    Response: "C·∫£m ∆°n b·∫°n ƒë√£ quan t√¢m! M√¨nh l√† chatbot t∆∞ v·∫•n du l·ªãch Vi·ªát Nam, s·∫µn s√†ng h·ªó tr·ª£ b·∫°n kh√°m ph√° c√°c ƒëi·ªÉm ƒë·∫øn tuy·ªát ƒë·∫πp, m√≥n ƒÉn h·∫•p d·∫´n v√† nhi·ªÅu ho·∫°t ƒë·ªông th√∫ v·ªã. H√£y h·ªèi m√¨nh b·∫•t c·ª© ƒëi·ªÅu g√¨ li√™n quan ƒë·∫øn du l·ªãch nh√©! üòä"
    User query: "·ªû ƒë√≥ c√≥ m√≥n g√¨ ngon?"
    Response: "no"
    User query: "B·∫°n c√≥ th√≠ch ƒëi du l·ªãch kh√¥ng?"
    Response: "M√¨nh l√† chatbot t∆∞ v·∫•n du l·ªãch Vi·ªát Nam, lu√¥n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n kh√°m ph√° c√°c ƒëi·ªÉm ƒë·∫øn tuy·ªát v·ªùi, ·∫©m th·ª±c h·∫•p d·∫´n v√† c√°c ho·∫°t ƒë·ªông th√∫ v·ªã. H√£y h·ªèi t√¥i b·∫•t k·ª≥ ƒëi·ªÅu g√¨ li√™n quan ƒë·∫øn du l·ªãch nh√©! üòä"
    User query: "H√† N·ªôi c√≥ m√≥n ƒÉn n√†o ngon nh·∫•t?"
    Response: "no"
    User query: "C√°c ƒë·ªãa ƒëi·ªÉm du l·ªãch n·ªïi ti·∫øng ·ªü Hu·∫ø l√† g√¨?"
    Response: "no"
    User query: "C·∫£m ∆°n b·∫°n"
    Response: "C·∫£m ∆°n b·∫°n ƒë√£ gh√© thƒÉm! M√¨nh l√† chatbot t∆∞ v·∫•n du l·ªãch Vi·ªát Nam, lu√¥n s·∫µn s√†ng gi√∫p b·∫°n kh√°m ph√° c√°c ƒëi·ªÉm ƒë·∫øn tuy·ªát v·ªùi, ·∫©m th·ª±c phong ph√∫ v√† nhi·ªÅu ho·∫°t ƒë·ªông th√∫ v·ªã. H√£y h·ªèi m√¨nh b·∫•t c·ª© ƒëi·ªÅu g√¨ li√™n quan ƒë·∫øn du l·ªãch nh√©!"
    ###D·ª±a tr√™n c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng, h√£y th·ª±c hi·ªán ƒë√∫ng y√™u c·∫ßu. C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng: {input_sentence}"""

    completion = client.chat.completions.create(
      model="gpt-4o-mini",
      messages=[
        {"role": "user", "content": prompt}
      ]
    )
    answer = completion.choices[0].message.content
    return answer.strip().lower()

def create_new_prompt(prompt, chat_history, user_query, **kwargs):
  new_prompt = f"{prompt} l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán: {chat_history} c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_query}"
  for key, value in kwargs.items():
    new_prompt += f" {key}: {value}"

  return new_prompt

def chatbot(conversation_history: List[Dict[str, str]], language) -> str:
    user_query = conversation_history[-1]['content']

    meta_corpus = load_meta_corpus(r"../data/corpus_chunks.jsonl")

    retriever = Retriever(
        corpus=meta_corpus,
        corpus_emb_path=r"../data/corpus_embedding_w150.pkl",
        model_name="bkai-foundation-models/vietnamese-bi-encoder"
    )

    # X·ª≠ l√Ω n·∫øu ng∆∞·ªùi d√πng c√≥ c√¢u h·ªèi nh·ªè ho·∫∑c tr√≤ chuy·ªán phi·∫øm
    result = classify_small_talk(user_query, language)
    print("result classify small talk:", result)
    if "no" not in result:
        return result

    elif "no" in result:
        prompt = """D·ª±a tr√™n l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán v√† c√¢u h·ªèi m·ªõi nh·∫•t c·ªßa ng∆∞·ªùi d√πng, c√≥ th·ªÉ tham chi·∫øu ƒë·∫øn ng·ªØ c·∫£nh trong l·ªãch s·ª≠ tr√≤ chuy·ªán, 
            h√£y t·∫°o th√†nh m·ªôt c√¢u h·ªèi ƒë·ªôc l·∫≠p c√≥ th·ªÉ hi·ªÉu ƒë∆∞·ª£c m√† kh√¥ng c·∫ßn l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán. 
            KH√îNG tr·∫£ l·ªùi c√¢u h·ªèi, ch·ªâ c·∫ßn ƒëi·ªÅu ch·ªânh l·∫°i n·∫øu c·∫ßn, n·∫øu kh√¥ng th√¨ gi·ªØ nguy√™n. 
            N·∫øu c√¢u h·ªèi b·∫±ng ti·∫øng Anh, sau khi tinh ch·ªânh, h√£y d·ªãch c√¢u h·ªèi ƒë√≥ sang ti·∫øng Vi·ªát."""

        # S·ª≠ d·ª•ng h√†m t·∫°o c√¢u h·ªèi m·ªõi t·ª´ l·ªãch s·ª≠ tr√≤ chuy·ªán
        new_prompt = create_new_prompt(
            prompt=prompt,
            chat_history=conversation_history,
            user_query=user_query,
        )

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": new_prompt}
            ]
        )

        answer = completion.choices[0].message.content
        print("C√¢u h·ªèi m·ªõi: ", answer)
        question = answer
        top_passages = retriever.retrieve(question, topk=10)
        print("topK:", top_passages)
        smoothed_contexts = smooth_contexts(top_passages, meta_corpus)
        print("Smooth context: ", smoothed_contexts)
        prompt = get_prompt(question, smoothed_contexts, language)
    
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        answer = completion.choices[0].message.content
        
        return answer

    else:
        print("Unexpected response from the model.")
        return "Xin l·ªói, h·ªá th·ªëng kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c."
    
# def main():
#     # Nh·∫≠n input t·ª´ ng∆∞·ªùi d√πng
#     user_query = input("User query: ")

#     result = chatbot(user_query)

#     # Tr·∫£ v·ªÅ output
#     print(result)

# if __name__ == "__main__":
#     main()
